{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "12S8E1TdJh3SdrL_ENz3EbhjXhWqr9S-8",
      "authorship_tag": "ABX9TyO5T6MQXfSz9g2MDvFFWt/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishamohamed/GAN-Benchmarck/blob/main/classify.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DCGAN-Augmented Melanoma Classification"
      ],
      "metadata": {
        "id": "jEU180C0xTdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DCGAN-Augmented Melanoma Classification\n",
        "\n",
        "**Author:** Aisha Mohamed\n",
        "**Supervisor:** Reihaneh Tarlani  \n",
        "**Course:** ISIC-2017 GAN Benchmarking (Bachelor’s Thesis, Spring 2025)  \n",
        "\n",
        "This notebook implements an end-to-end pipeline for augmenting a ResNet-18 skin lesion classifier with DCGAN-generated synthetic melanoma images. We compare baseline (real-only) performance with augmented training using 200 and 500 synthetic samples."
      ],
      "metadata": {
        "id": "WSgUQ_drxpms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Environment Setup"
      ],
      "metadata": {
        "id": "7SaX4Aurx9e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#imports\n",
        "import os, glob\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset\n",
        "from torchvision import transforms as T, datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from pathlib import Path\n",
        "from torchvision import models\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "from sklearn.metrics import classification_report\n",
        "import random\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Running on:\", device)\n"
      ],
      "metadata": {
        "id": "j1-6oWm4xCl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb9b642f-caea-4fe8-9d21-b023b3ed967b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Paths & Hyperparameters"
      ],
      "metadata": {
        "id": "HHCOPldqyo3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# filesystem & paths\n",
        "from pathlib import Path\n",
        "BASE     = Path('/content/drive/MyDrive/ISIC2017')\n",
        "REAL_ROOT= BASE / 'by_class_128'\n",
        "SYN_ROOT = BASE / 'synthetic_melanoma'\n",
        "TEST_ROOT= BASE / 'test_by_class'\n",
        "\n",
        "# hyperparameters\n",
        "image_size = 128\n",
        "batch_size = 32\n",
        "num_epochs = 5\n",
        "lr         = 1e-4\n",
        "nz         = 100    # latent dim for your DCGAN (adjust if yours differs)\n",
        "nz  = 100   # latent vector size\n",
        "ngf = 64    # generator feature-map base size\n",
        "nc  = 3     # number of image channels (RGB)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "exIMEhF7Tdae"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Transforms & Loaders"
      ],
      "metadata": {
        "id": "pqAMovjpyDdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Common preprocessing transform\n",
        "clf_tf = T.Compose([\n",
        "    T.Resize(image_size),\n",
        "    T.CenterCrop(image_size),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# real-only loader\n",
        "real_ds    = datasets.ImageFolder(str(REAL_ROOT), transform=clf_tf)\n",
        "real_loader= DataLoader(real_ds, batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "\n",
        "# Synthetic-only placeholder loader (will load 'melanoma' class)\n",
        "syn_ds     = datasets.ImageFolder(str(SYN_ROOT), transform=clf_tf)\n",
        "syn_loader = DataLoader(syn_ds,    batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "\n",
        "# Combined augmented loader\n",
        "aug_ds     = ConcatDataset([real_ds, syn_ds])\n",
        "aug_loader = DataLoader(aug_ds,    batch_size=batch_size, shuffle=True,  num_workers=2)\n",
        "\n",
        "# Test loader\n",
        "test_ds    = datasets.ImageFolder(str(TEST_ROOT), transform=clf_tf)\n",
        "test_loader= DataLoader(test_ds,   batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "print(\"Real classes:\", real_ds.classes, \"=>\", len(real_ds))\n",
        "print(\"Synth  classes:\", syn_ds.classes, \"=>\", len(syn_ds))\n",
        "print(\"Augmented total:\", len(aug_ds))\n",
        "print(\"Test   total:\", len(test_ds))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHJdA-DjUa-k",
        "outputId": "a2daf8c4-d17b-41bb-e2ef-82d62bd0d313"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real classes: ['melanoma', 'nevus', 'seborrheic_keratosis'] => 2000\n",
            "Synth  classes: ['melanoma'] => 1000\n",
            "Augmented total: 3000\n",
            "Test   total: 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DCGAN Generator Definition & Loading"
      ],
      "metadata": {
        "id": "XXSKZqiGzFUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DCGAN Generator (matches training architecture)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # nz × 1 × 1 → ngf*8 × 4 × 4\n",
        "            nn.ConvTranspose2d(nz, ngf*8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),\n",
        "            # → ngf*4 × 8 × 8\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),\n",
        "            # → ngf*2 × 16 × 16\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),\n",
        "            # → ngf × 32 × 32\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf), nn.ReLU(True),\n",
        "            # → nc=3 × 64 × 64\n",
        "            nn.ConvTranspose2d(ngf, 3, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "# Instantiate & load saved weights\n",
        "generator = Generator().to(device)\n",
        "\n",
        "gen_path = '/content/drive/MyDrive/ISIC2017/models/dcgan_generator_final.pth'\n",
        "state    = torch.load(gen_path, map_location=device)\n",
        "generator.load_state_dict(state)\n",
        "\n",
        "generator.eval()\n",
        "print(\"Loaded DCGAN generator from\", gen_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nN3xQhMdJHi",
        "outputId": "67328604-ecf3-4bb9-ba4a-3b88aea540ac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded DCGAN generator from /content/drive/MyDrive/ISIC2017/models/dcgan_generator_final.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Classifier & Save Initial Weights"
      ],
      "metadata": {
        "id": "MoY-K6V6z47x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_classifier(num_classes):\n",
        "    model = models.resnet18(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    return model.to(device)\n",
        "\n",
        "# initial model & save its “fresh” state for reset\n",
        "model = make_classifier(len(real_ds.classes))\n",
        "torch.save(model.state_dict(), '/content/initial_resnet18.pth')\n",
        "\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "DdmSCHH1YhGi",
        "outputId": "17228bcf-5285-43f3-930b-44b1b544b4da"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Evaluation Routines"
      ],
      "metadata": {
        "id": "2onahe7J0H5g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for imgs, labs in dataloader:\n",
        "        imgs, labs = imgs.to(device), labs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(imgs)\n",
        "        loss   = criterion(logits, labs)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item() * imgs.size(0)\n",
        "    return total_loss / len(dataloader.dataset)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    for imgs, labs in loader:\n",
        "        imgs = imgs.to(device)\n",
        "        logits = model(imgs)\n",
        "        preds  = logits.argmax(dim=1).cpu().tolist()\n",
        "        all_preds.extend(preds)\n",
        "        all_labels.extend(labs.tolist())\n",
        "    return all_labels, all_preds\n"
      ],
      "metadata": {
        "id": "nQMycycnYiS3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Baseline (Real-Only) Training & Eval"
      ],
      "metadata": {
        "id": "10pvo-LK0QrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reload fresh model & optimizer\n",
        "model.load_state_dict(torch.load('/content/initial_resnet18.pth'))\n",
        "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "print(\"=> Baseline (real-only) training\")\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    loss = train_one_epoch(real_loader)\n",
        "    print(f\"[Baseline] Epoch {epoch}/{num_epochs}  Loss: {loss:.4f}\")\n",
        "\n",
        "y_true, y_pred = evaluate(test_loader)\n",
        "print(\"\\nBaseline test report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=real_ds.classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7i5NHM6YjR0",
        "outputId": "de7f4335-0fe8-484d-9cda-c0473fb32ed8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "→ Baseline (real-only) training\n",
            "[Baseline] Epoch 1/5  Loss: 0.6881\n",
            "[Baseline] Epoch 2/5  Loss: 0.2142\n",
            "[Baseline] Epoch 3/5  Loss: 0.0660\n",
            "[Baseline] Epoch 4/5  Loss: 0.0230\n",
            "[Baseline] Epoch 5/5  Loss: 0.0124\n",
            "\n",
            "Baseline test report:\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "            melanoma       0.55      0.31      0.40       117\n",
            "               nevus       0.73      0.88      0.80       393\n",
            "seborrheic_keratosis       0.45      0.29      0.35        90\n",
            "\n",
            "            accuracy                           0.68       600\n",
            "           macro avg       0.58      0.49      0.51       600\n",
            "        weighted avg       0.65      0.68      0.65       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.utils as vutils\n",
        "\n",
        "out_dir = SYN_ROOT / 'melanoma'\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "generator.eval()\n",
        "noise = torch.randn(500, nz, 1, 1, device=device)\n",
        "fake_imgs = generator(noise).cpu()\n",
        "fake_imgs = (fake_imgs + 1) / 2     # rescale [-1,1]→[0,1]\n",
        "\n",
        "for i, img in enumerate(fake_imgs):\n",
        "    vutils.save_image(img, out_dir / f\"dcgan_{i:03d}.png\")\n",
        "print(\" Generated 500 synthetic melanoma images\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-uzxBNdYlJb",
        "outputId": "fd8dd22d-3e44-4451-849d-fe72667cc070"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Generated 500 synthetic melanoma images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Augmentation Subsampling Helper"
      ],
      "metadata": {
        "id": "4OANNyGN16Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Subset\n",
        "\n",
        "def make_aug_loader(n_syn: int):\n",
        "    full_syn = datasets.ImageFolder(str(SYN_ROOT), transform=clf_tf)\n",
        "    N = len(full_syn)\n",
        "    if n_syn > N:\n",
        "        raise ValueError(f\"Requested {n_syn} synthetic > available {N}\")\n",
        "    idxs   = np.random.choice(N, size=n_syn, replace=False).tolist()\n",
        "    syn_sub= Subset(full_syn, idxs)\n",
        "    aug_ds = ConcatDataset([real_ds, syn_sub])\n",
        "    loader = DataLoader(\n",
        "        aug_ds, batch_size=batch_size, shuffle=True,\n",
        "        num_workers=2, pin_memory=True\n",
        "    )\n",
        "    print(f\"Augmented: real {len(real_ds)} + syn {n_syn} = {len(aug_ds)}\")\n",
        "    return loader"
      ],
      "metadata": {
        "id": "B0pSoBSFtznV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for n_syn in [200, 500]:\n",
        "    print(f\"\\n===== Augmented run with {n_syn} synthetic images =====\")\n",
        "    # reset model & optimizer\n",
        "    model.load_state_dict(torch.load('/content/initial_resnet18.pth', map_location=device))\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    # build a loader with exactly n_syn fakes\n",
        "    loader = make_aug_loader(n_syn)\n",
        "\n",
        "    # train\n",
        "    for epoch in range(1, num_epochs+1):\n",
        "        loss = train_one_epoch(loader)\n",
        "        print(f\"[Aug ({n_syn})] Epoch {epoch}/{num_epochs}  Loss: {loss:.4f}\")\n",
        "\n",
        "    # eval\n",
        "    y_true_aug, y_pred_aug = evaluate(test_loader)\n",
        "    print(f\"\\nTest report (n_syn={n_syn}):\")\n",
        "    print(classification_report(y_true_aug, y_pred_aug, target_names=real_ds.classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEyd13Ibuqhy",
        "outputId": "0104e56b-858a-4bfc-f8f4-f11ebe5fa078"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== Augmented run with 200 synthetic images =====\n",
            "Augmented: real 2000 + syn 200 = 2200\n",
            "[Aug (200)] Epoch 1/5  Loss: 0.7158\n",
            "[Aug (200)] Epoch 2/5  Loss: 0.2017\n",
            "[Aug (200)] Epoch 3/5  Loss: 0.0618\n",
            "[Aug (200)] Epoch 4/5  Loss: 0.0260\n",
            "[Aug (200)] Epoch 5/5  Loss: 0.0159\n",
            "\n",
            "Test report (n_syn=200):\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "            melanoma       0.33      0.71      0.45       117\n",
            "               nevus       0.79      0.56      0.66       393\n",
            "seborrheic_keratosis       0.39      0.31      0.35        90\n",
            "\n",
            "            accuracy                           0.55       600\n",
            "           macro avg       0.50      0.53      0.48       600\n",
            "        weighted avg       0.64      0.55      0.57       600\n",
            "\n",
            "\n",
            "===== Augmented run with 500 synthetic images =====\n",
            "Augmented: real 2000 + syn 500 = 2500\n",
            "[Aug (500)] Epoch 1/5  Loss: 0.6299\n",
            "[Aug (500)] Epoch 2/5  Loss: 0.1885\n",
            "[Aug (500)] Epoch 3/5  Loss: 0.0661\n",
            "[Aug (500)] Epoch 4/5  Loss: 0.0639\n",
            "[Aug (500)] Epoch 5/5  Loss: 0.0674\n",
            "\n",
            "Test report (n_syn=500):\n",
            "                      precision    recall  f1-score   support\n",
            "\n",
            "            melanoma       0.31      0.56      0.39       117\n",
            "               nevus       0.79      0.61      0.69       393\n",
            "seborrheic_keratosis       0.43      0.40      0.42        90\n",
            "\n",
            "            accuracy                           0.57       600\n",
            "           macro avg       0.51      0.52      0.50       600\n",
            "        weighted avg       0.64      0.57      0.59       600\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), str(BASE / 'final_resnet18_dcgan_aug.pth'))\n",
        "print(\"Saved augmented model weights\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8YdXGSK2WN0",
        "outputId": "97d2a8d8-fa4d-4858-9701-29903371b915"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved augmented model weights\n"
          ]
        }
      ]
    }
  ]
}